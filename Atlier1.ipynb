{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfcbf40c",
   "metadata": {},
   "source": [
    "# Partie 1 : Pré-traitement de texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4898452d",
   "metadata": {},
   "source": [
    "# 1. Créer un corpus qui contient les textes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a75b107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"Le chat dort sur le tapis.\",\n",
    "          \"Les Oiseaux Chantent Le Matin.\",\n",
    "          \"Le chien court dans le jardin.\",\n",
    "          \"Mangeons des pommes délicieuses.\",\n",
    "          \"Je mange une orange fraîche.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc074a2",
   "metadata": {},
   "source": [
    "# 2. Convertir le corpus en type DataFrame :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a1a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(corpus, columns=['texte_original'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6ceeeb",
   "metadata": {},
   "source": [
    "# 3 Ecrire code suivant : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5494a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7946f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code(texte):\n",
    "    text_s_pon = [c for c in texte if c not in string.punctuation]\n",
    "    return ''.join(text_s_pon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c74e148",
   "metadata": {},
   "source": [
    "# 5. Ajouter une colonne dans l’objet corpus nommée « t_s_p » en utilisant la fonction de Q.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54853394",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['t_s_p'] = df['texte_original'].apply(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f3504b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texte_original</th>\n",
       "      <th>t_s_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Le chat dort sur le tapis.</td>\n",
       "      <td>Le chat dort sur le tapis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Les Oiseaux Chantent Le Matin.</td>\n",
       "      <td>Les Oiseaux Chantent Le Matin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le chien court dans le jardin.</td>\n",
       "      <td>Le chien court dans le jardin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mangeons des pommes délicieuses.</td>\n",
       "      <td>Mangeons des pommes délicieuses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Je mange une orange fraîche.</td>\n",
       "      <td>Je mange une orange fraîche</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     texte_original                            t_s_p\n",
       "0        Le chat dort sur le tapis.        Le chat dort sur le tapis\n",
       "1    Les Oiseaux Chantent Le Matin.    Les Oiseaux Chantent Le Matin\n",
       "2    Le chien court dans le jardin.    Le chien court dans le jardin\n",
       "3  Mangeons des pommes délicieuses.  Mangeons des pommes délicieuses\n",
       "4      Je mange une orange fraîche.      Je mange une orange fraîche"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcecc376",
   "metadata": {},
   "source": [
    "# 6. Ecrire une fonction pour tokenizer le corpus de colonne « t_s_p » :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc6f31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Lehcene\n",
      "[nltk_data]     Mohamed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def tokenization_and_preprocessing_function(text):\n",
    "    tokens = word_tokenize(text.lower())  # Tokenization et conversion en minuscules\n",
    "    return tokens  # Rejoindre les tokens en une seule chaîne de texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73220915",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['t_tokenize'] = df['t_s_p'].apply(tokenization_and_preprocessing_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fa9176b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texte_original</th>\n",
       "      <th>t_s_p</th>\n",
       "      <th>t_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Le chat dort sur le tapis.</td>\n",
       "      <td>Le chat dort sur le tapis</td>\n",
       "      <td>[le, chat, dort, sur, le, tapis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Les Oiseaux Chantent Le Matin.</td>\n",
       "      <td>Les Oiseaux Chantent Le Matin</td>\n",
       "      <td>[les, oiseaux, chantent, le, matin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le chien court dans le jardin.</td>\n",
       "      <td>Le chien court dans le jardin</td>\n",
       "      <td>[le, chien, court, dans, le, jardin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mangeons des pommes délicieuses.</td>\n",
       "      <td>Mangeons des pommes délicieuses</td>\n",
       "      <td>[mangeons, des, pommes, délicieuses]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Je mange une orange fraîche.</td>\n",
       "      <td>Je mange une orange fraîche</td>\n",
       "      <td>[je, mange, une, orange, fraîche]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     texte_original                            t_s_p  \\\n",
       "0        Le chat dort sur le tapis.        Le chat dort sur le tapis   \n",
       "1    Les Oiseaux Chantent Le Matin.    Les Oiseaux Chantent Le Matin   \n",
       "2    Le chien court dans le jardin.    Le chien court dans le jardin   \n",
       "3  Mangeons des pommes délicieuses.  Mangeons des pommes délicieuses   \n",
       "4      Je mange une orange fraîche.      Je mange une orange fraîche   \n",
       "\n",
       "                             t_tokenize  \n",
       "0      [le, chat, dort, sur, le, tapis]  \n",
       "1   [les, oiseaux, chantent, le, matin]  \n",
       "2  [le, chien, court, dans, le, jardin]  \n",
       "3  [mangeons, des, pommes, délicieuses]  \n",
       "4     [je, mange, une, orange, fraîche]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dae2404",
   "metadata": {},
   "source": [
    "# 7. Ecrire une fonction qui élimine les stop words :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5f708cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Lehcene\n",
      "[nltk_data]     Mohamed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7515250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    stop_words = set(stopwords.words('french'))\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c98feb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_after_remove_stop_word\"] = df[\"t_tokenize\"].apply(remove_stopwords)  # Appliquez remove_stopwords sur les listes de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b45e847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texte_original</th>\n",
       "      <th>t_s_p</th>\n",
       "      <th>t_tokenize</th>\n",
       "      <th>text_after_remove_stop_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Le chat dort sur le tapis.</td>\n",
       "      <td>Le chat dort sur le tapis</td>\n",
       "      <td>[le, chat, dort, sur, le, tapis]</td>\n",
       "      <td>[chat, dort, tapis]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               texte_original                      t_s_p  \\\n",
       "0  Le chat dort sur le tapis.  Le chat dort sur le tapis   \n",
       "\n",
       "                         t_tokenize text_after_remove_stop_word  \n",
       "0  [le, chat, dort, sur, le, tapis]         [chat, dort, tapis]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d83a9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Lehcene\n",
      "[nltk_data]     Mohamed\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf461acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lemmatization_and_stemming(text):\n",
    "    text = ' '.join(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(stemmer.stem(word)) for word in tokens]\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b08d3ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lemmatization_and_stemming_with_corpus_with_have_any_stop_words\"]=df[\"text_after_remove_stop_word\"].apply(apply_lemmatization_and_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48541046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texte_original</th>\n",
       "      <th>t_s_p</th>\n",
       "      <th>t_tokenize</th>\n",
       "      <th>text_after_remove_stop_word</th>\n",
       "      <th>lemmatization_and_stemming_with_corpus_with_have_any_stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Le chat dort sur le tapis.</td>\n",
       "      <td>Le chat dort sur le tapis</td>\n",
       "      <td>[le, chat, dort, sur, le, tapis]</td>\n",
       "      <td>[chat, dort, tapis]</td>\n",
       "      <td>[chat, dort, tapi]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               texte_original                      t_s_p  \\\n",
       "0  Le chat dort sur le tapis.  Le chat dort sur le tapis   \n",
       "\n",
       "                         t_tokenize text_after_remove_stop_word  \\\n",
       "0  [le, chat, dort, sur, le, tapis]         [chat, dort, tapis]   \n",
       "\n",
       "  lemmatization_and_stemming_with_corpus_with_have_any_stop_words  \n",
       "0                                 [chat, dort, tapi]               "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337595aa",
   "metadata": {},
   "source": [
    "# Partie 2 : CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3618b15",
   "metadata": {},
   "source": [
    "# 9. Initialiser et ajuster le CountVectorizer à votre corpus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0af1b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['t_s_p'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2d1b92",
   "metadata": {},
   "source": [
    "# 10. Transformer le corpus en une matrice de comptage de tokens :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b8e00c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e754a9c0",
   "metadata": {},
   "source": [
    "# 11. Explorer la matrice résultante pour comprendre comment les tokens sont représentés en vecteurs binaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b24e61c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   chantent  chat  chien  court  dans  des  dort  délicieuses  fraîche  \\\n",
      "0         0     1      0      0     0    0     1            0        0   \n",
      "1         1     0      0      0     0    0     0            0        0   \n",
      "2         0     0      1      1     1    0     0            0        0   \n",
      "3         0     0      0      0     0    1     0            1        0   \n",
      "4         0     0      0      0     0    0     0            0        1   \n",
      "\n",
      "   jardin  ...  les  mange  mangeons  matin  oiseaux  orange  pommes  sur  \\\n",
      "0       0  ...    0      0         0      0        0       0       0    1   \n",
      "1       0  ...    1      0         0      1        1       0       0    0   \n",
      "2       1  ...    0      0         0      0        0       0       0    0   \n",
      "3       0  ...    0      0         1      0        0       0       1    0   \n",
      "4       0  ...    0      1         0      0        0       1       0    0   \n",
      "\n",
      "   tapis  une  \n",
      "0      1    0  \n",
      "1      0    0  \n",
      "2      0    0  \n",
      "3      0    0  \n",
      "4      0    1  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "count_df = pd.DataFrame(count_matrix, columns=feature_names)\n",
    "print(count_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e20f34",
   "metadata": {},
   "source": [
    "# Partie 3 : TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f2e61",
   "metadata": {},
   "source": [
    "# 1. Initialiser et ajuster le TfidfVectorizer à votre corpus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a34e4dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['t_s_p'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ca387",
   "metadata": {},
   "source": [
    "# 2. Transformer le corpus en une matrice de poids de tokens dans le corpus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cad2b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0754f11",
   "metadata": {},
   "source": [
    "# 3. Explorer la matrice résultante pour comprendre comment les tokens sont représentés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbeaa4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   chantent     chat    chien    court     dans  des     dort  délicieuses  \\\n",
      "0  0.000000  0.41544  0.00000  0.00000  0.00000  0.0  0.41544          0.0   \n",
      "1  0.474125  0.00000  0.00000  0.00000  0.00000  0.0  0.00000          0.0   \n",
      "2  0.000000  0.00000  0.41544  0.41544  0.41544  0.0  0.00000          0.0   \n",
      "3  0.000000  0.00000  0.00000  0.00000  0.00000  0.5  0.00000          0.5   \n",
      "4  0.000000  0.00000  0.00000  0.00000  0.00000  0.0  0.00000          0.0   \n",
      "\n",
      "    fraîche   jardin  ...       les     mange  mangeons     matin   oiseaux  \\\n",
      "0  0.000000  0.00000  ...  0.000000  0.000000       0.0  0.000000  0.000000   \n",
      "1  0.000000  0.00000  ...  0.474125  0.000000       0.0  0.474125  0.474125   \n",
      "2  0.000000  0.41544  ...  0.000000  0.000000       0.0  0.000000  0.000000   \n",
      "3  0.000000  0.00000  ...  0.000000  0.000000       0.5  0.000000  0.000000   \n",
      "4  0.447214  0.00000  ...  0.000000  0.447214       0.0  0.000000  0.000000   \n",
      "\n",
      "     orange  pommes      sur    tapis       une  \n",
      "0  0.000000     0.0  0.41544  0.41544  0.000000  \n",
      "1  0.000000     0.0  0.00000  0.00000  0.000000  \n",
      "2  0.000000     0.0  0.00000  0.00000  0.000000  \n",
      "3  0.000000     0.5  0.00000  0.00000  0.000000  \n",
      "4  0.447214     0.0  0.00000  0.00000  0.447214  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "tfidf_df = pd.DataFrame(tfidf_matrix, columns=feature_names)\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e482c3",
   "metadata": {},
   "source": [
    "# 4. Appliquer la métrique similarité de cosinus entre les tokens « chat et chien », puis après « pomme et orange » sur les deux représentations vectorielles. Conclure ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "061d6ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarité de cosinus entre 'chat' et 'chien': 0.0\n",
      "Similarité de cosinus entre 'pomme' et 'orange': 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity_chat_chien = cosine_similarity(tfidf_df[['chat']], tfidf_df[['chien']])[0][0]\n",
    "cosine_similarity_pomme_orange = cosine_similarity(tfidf_df[['pommes']], tfidf_df[['orange']])[0][0]\n",
    "\n",
    "print(\"Similarité de cosinus entre 'chat' et 'chien':\", cosine_similarity_chat_chien)\n",
    "print(\"Similarité de cosinus entre 'pomme' et 'orange':\", cosine_similarity_pomme_orange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb4c391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
